## Disclaimer:
# This playbook is not officially supported and comes with no guarantees.
# Use it at your own risk. Ensure you test thoroughly in your environment
# before deploying to production.

# This Ansible playbook is designed for deploying an OpenShift cluster.
# It includes various roles and tasks necessary to configure a bastion host,
# deploy virtual machines (VMs), and boot bare-metal (BM) and VM nodes.
# The playbook also sets up dependencies, generates manifests, and monitors the installation process.

## Overview:
# This playbook automates the process of deploying ocp cluster. It includes:
# - Bastion host setup: Installs required dependencies and extracts OpenShift installer.
# - OCP version facts: Retrieves OpenShift release information.
# - HTTP storage setup: Configures HTTP-based storage for required artifacts.
# - Virtual control plane setup: Enables necessary repositories and configures sushy tools.
# - VM and BM booting: Deploys instances and boots nodes using an agent-based installer.
# - Installation monitoring: Ensures the installation process completes successfully.
# - Deploying additional cluster-wide trusted registries.
# - Optional internal registry flow: when `internal_registry: true`, configure DNS for the
#     internal registry, add auth to the cluster pull-secret, and trust the registry CA by
#     creating `openshift-config/<internal_registry_name>` ConfigMap with key `host..port`
#     (colon replaced by two dots) and patching `image.config.openshift.io/cluster` with
#     `spec.additionalTrustedCA.name`.

## Prerequisites:
# - Ansible 2.10+ installed on the control node.
# - Ansible control node configured with necessary permissions.
# - SSH Access to hypervisors hosts.
# - SSH Access to bastion hosts.
# - ocp version of link to ocp release
# - pre-configured hosts_vars and grup_vars directories

# optional variables:
# - extra_manifests: list of extra manifests for OCP installation
# - internal_registry (bool): enable internal registry preparation and CA trust

## Roles Requirements
# The playbook uses role:
# - redhatci.ocp.create_vms: Creates VMs on given hypervisor.

# Required Roles:
# The playbook uses roles:
# - ocp_version_facts
# - redhatci.ocp.setup_http_store
# - ocp_client
# - redhatci.ocp.extract_openshift_installer
# - redhatci.ocp.generate_manifests
# - redhatci.ocp.generate_agent_iso
# - redhatci.ocp.process_kvm_nodes
# - redhatci.ocp.setup_sushy_tools
# - redhatci.ocp.destroy_vms
# - redhatci.ocp.create_vms
# - redhatci.ocp.boot_iso
# - redhatci.ocp.monitor_agent_based_installer

## Usage:
# - Ensure all required variables are defined in the inventory or host_vars/group_vars.
# - Execute the playbook using Ansible's command-line tool:
#
#   Deploy latest 4.17
#     ansible-playbook ./playbooks/deploy-ocp-hybrid-multinode.yml -i ./inventories/ocp-deployment/deploy-ocp-hybrid-multinode.yml --extra-vars 'release=4.17'
#   Deploy specific release from link:
#     ansible-playbook ./playbooks/deploy-ocp-hybrid-multinode.yml -i ./inventories/ocp-deployment/deploy-ocp-hybrid-multinode.yml
#       --extra-vars 'release=quay.io/openshift-release-dev/ocp-release:4.15.44-x86_64'
#   Deploy specific version:
#     ansible-playbook ./playbooks/deploy-ocp-hybrid-multinode.yml -i ./inventories/ocp-deployment/deploy-ocp-hybrid-multinode.yml --extra-vars 'release=4.17.9'
#   Deploy with trusted internal registry:
#     ansible-playbook ./playbooks/deploy-ocp-hybrid-multinode.yml -i ./inventories/ocp-deployment/deploy-ocp-hybrid-multinode.yml
#       --extra-vars "release=4.17.9 internal_registry=true"

## Optional Environment Variables (for each worker node):
# - <inventory_hostname>_EXTERNAL_INTERFACE:   Name of the external network interface. Example worker0_EXTERNAL_INTERFACE=eth2
# - <inventory_hostname>_MAC_ADDRESS:          MAC address of the external network interface. Example worker0_MAC_ADDRESS=aa:bb:cc:aa:bb:cc
# If these environment variables are set and non-empty:
# - Update 'network_config' to use the provided external interface name and MAC address.
# - Update 'mac_interface_map' accordingly.

# Notes:
# - This playbook assumes the hypervisor and bastion hosts are pre-installed and ready.
# - Test in a non-production environment before deploying.
---
- name: Render nodes variables
  hosts: nodes
  gather_facts: false
  vars:
    internal_registry: false
  tasks:
    - name: Render nodes variables
      delegate_to: bastion
      ansible.builtin.set_fact:
        network_config: "{{ network_config_string | from_yaml }}"
        mac_interface_map: "{{ mac_interface_map_string | from_yaml }}"

    - name: Render VM spec from YAML string
      ansible.builtin.set_fact:
        vm_spec: "{{ vm_spec_string | from_yaml }}"
        network_interfaces: "{{ network_interfaces_string | from_yaml }}"
      when: vendor | lower == 'kvm'

    - name: Process KVM nodes to set facts
      ansible.builtin.import_role:
        name: redhatci.ocp.process_kvm_nodes

    - name: Replace DNS servers with internal registry
      when: (internal_registry | bool)
      ansible.builtin.set_fact:
        network_config: >-
          {{
            network_config | combine({
              "raw": network_config.raw | combine({
                "dns-resolver": {
                  "config": {
                    "server": [ hostvars['bastion']['ansible_host'] ]
                  },
                },
              })
            }, recursive=True)
          }}

# Process optional environment Variables if present
- name: Mutate worker network configuration if env variables are present
  hosts: workers
  gather_facts: false
  tasks:

    - name: Set env EXTERNAL_INTERFACE variable name
      ansible.builtin.set_fact:
        iface_env_var_name: "{{ inventory_hostname + '_EXTERNAL_INTERFACE' }}"

    - name: Set env MAC_ADDRESS variable name
      ansible.builtin.set_fact:
        mac_addr_env_var_name: "{{ inventory_hostname + '_MAC_ADDRESS' }}"

    - name: Set fact from environment variable
      ansible.builtin.set_fact:
        external_interface_name: "{{ lookup('env', iface_env_var_name) }}"
        external_interface_mac: "{{ lookup('env', mac_addr_env_var_name) }}"

    - name: Mutate ocp deployment network settings if env variables are present
      when:
        - external_interface_name is defined
        - external_interface_name | length > 0
        - external_interface_mac is defined
        - external_interface_mac | length > 0
      block:
        - name: Mutate network config using env variables
          ansible.builtin.set_fact:
            network_config: >-
              {{
                network_config | combine({
                  'raw': network_config.raw | combine({
                    'interfaces': network_config.raw.interfaces | map('combine', {
                      'name': external_interface_name,
                      'mac-address': external_interface_mac
                    }) | list,
                    'routes': {
                      'config': network_config.raw.routes.config | map('combine', {
                        'next-hop-interface': external_interface_name
                      }) | list
                    }
                  })
                })
              }}

        - name: Mutate mac interface map config using env variables
          ansible.builtin.set_fact:
            mac_interface_map: >-
              {{
                mac_interface_map | map('combine', {
                  'logical_nic_name': external_interface_name,
                  'mac_address': external_interface_mac
                }) | list
              }}

- name: Render masters variables
  hosts: masters
  gather_facts: false
  tasks:
    - name: Render masters variables
      delegate_to: bastion
      ansible.builtin.set_fact:
        network_interfaces: "{{ network_interfaces_string | from_yaml }}"

- name: Setup bastion environment and generate manifests for cluster deployment
  hosts: bastion
  vars:
    internal_registry: false
    release: "4.17"
    pull_secret: "{{ pull_secret_string | b64decode }}"
    registry_service_name: container-registry
  tasks:

    - name: Render bastion variables
      delegate_to: bastion
      ansible.builtin.set_fact:
        extra_cluster_networks: "{{ extra_cluster_networks_string | from_yaml }}"
        cluster_network_host_prefix: "{{ cluster_network_host_prefix | from_yaml }}"
        extra_machine_networks: "{{ extra_machine_networks_string | from_yaml }}"
        extra_service_networks: "{{ extra_service_networks_string | from_yaml }}"
        api_vips: "{{ api_vips_string | from_yaml }}"
        ingress_vips: "{{ ingress_vips_string | from_yaml }}"

    - name: Prepare disconnected infrastructure
      become: true
      when: internal_registry | bool
      block:
        - name: Ensure cluster name is set
          ansible.builtin.assert:
            that:
              - cluster_name is defined
            fail_msg: "Please provide cluster_name variable to playbook"

        - name: Ensure firewalld is running
          become: true
          ansible.builtin.service:
            name: firewalld
            state: started

        - name: Ensure DNS ports are open in firewalld
          loop:
            - 53/udp
            - 53/tcp
          loop_control:
            loop_var: port
          ansible.posix.firewalld:
            port: "{{ port }}"
            permanent: true
            state: enabled
            immediate: true

        - name: Install dnsmasq
          ansible.builtin.package:
            name: dnsmasq
            state: present

        - name: Restart dnsmasq
          ansible.builtin.service:
            name: dnsmasq
            enabled: true
            state: stopped

        - name: Configure dnsmasq main configuration
          ansible.builtin.template:
            src: dnsmasq.conf.j2
            dest: /etc/dnsmasq.conf
            owner: root
            group: root
            mode: '0644'

        - name: Create custom DNS records
          ansible.builtin.copy:
            dest: /etc/dnsmasq.d/custom-records.conf
            content: |
              address=/{{ disconnected_registry_url }}/{{ ansible_host }}
              {% if ansible_default_ipv6.address is defined and ansible_default_ipv6.address | length %}
              address=/{{ disconnected_registry_url }}/{{ ansible_default_ipv6.address }}
              {% endif %}
            owner: root
            group: root
            mode: '0644'

        - name: Restart dnsmasq
          ansible.builtin.service:
            name: dnsmasq
            enabled: true
            state: started

        - name: Add registry credentials to pull secret
          ansible.builtin.set_fact:
            pull_secret: >-
              {{
                pull_secret | combine({
                  'auths': pull_secret.auths | combine({
                    (disconnected_registry_url ~ ':' ~ disconnected_registry_port): {
                      'auth': ((ansible_user ~ ':' ~ ansible_password) | b64encode)
                    }
                  })
                }, recursive=True)
              }}

        - name: Stop registry service
          become: true
          ansible.builtin.systemd:
            name: "{{ registry_service_name }}"
            state: stopped

        - name: Remove registry data directory
          become: true
          ansible.builtin.file:
            path: /opt/registry/data/docker
            state: absent

        - name: Start registry service
          become: true
          ansible.builtin.systemd:
            name: "{{ registry_service_name }}"
            state: started

    - name: Set openshift-installer path fact
      ansible.builtin.set_fact:
        openshift_installer_extract_dest_path: "{{ dest_iso_dir }}/wip/extract"

    - name: Ensure cluster_name variable is set
      ansible.builtin.assert:
        that:
          - cluster_name is defined
        fail_msg: "Please provide cluster_name variable to playbook"

    - name: Install dependencies required for the installer
      become: true
      ansible.builtin.dnf:
        name:
          - nmstate
        state: present

    - name: Ensure firewalld is running
      become: true
      ansible.builtin.service:
        name: firewalld
        state: started

    # The role below sets follwing facts. Please note values are just examples
    # ocp_version_facts_pull_spec: quay.io/openshift-release-dev/ocp-release:4.15.44-x86_64
    # ocp_version_facts_parsed_release: "4.15.44"
    # ocp_version_facts_major: "4"
    # ocp_version_facts_minor: "15"
    # ocp_version_facts_oc_client_pull_link:
    #   "https://openshift-release-artifacts.apps.ci.l2s4.p1.openshiftapps.com/4.15.44/openshift-client-linux-4.15.44.tar.gz"
    # ocp_version_facts_z_stream: "44"
    # ocp_version_facts_dev_version: "rc1"
    - name: Set OCP version facts
      ansible.builtin.import_role:
        name: ocp_version_facts
      vars:
        ocp_version_facts_release: "{{ release }}"
        ocp_version_release_age_max_days: "{{ release_age_max_days | default(10000) | int }}"

    - name: Setup HTTP storage
      ansible.builtin.import_role:
        name: redhatci.ocp.setup_http_store
      vars:
        http_port: "{{ share_http_iso_port }}"

    - name: Deploy/Redeploy OCP client
      ansible.builtin.import_role:
        name: oc_client_install
      vars:
        oc_client_install_url: "{{ ocp_version_facts_oc_client_pull_link }}"
        oc_client_install_archive_dest_dir: "{{ dest_iso_dir }}"
        oc_clinet_install_version: "{{ ocp_version_facts_parsed_release }}"

    - name: Download and extract OCP installer
      ansible.builtin.import_role:
        name: redhatci.ocp.extract_openshift_installer
      vars:
        openshift_version: "{{ ocp_version_facts_parsed_release }}"
        release_image: "{{ ocp_version_facts_pull_spec }}"
        extract_dest_path: "{{ openshift_installer_extract_dest_path }}"

    - name: Generate deployment manifests for OCP installation
      ansible.builtin.import_role:
        name: redhatci.ocp.generate_manifests

    - name: Get stats for each file
      ansible.builtin.stat:
        path: "{{ item }}"
      loop: "{{ extra_manifests }}"
      register: extra_manifests_stats
      when:
        - extra_manifests is defined
        - extra_manifests | length > 0

    - name: Assert extra manifests path exists
      ansible.builtin.assert:
        that:
          - item.stat.exists
        fail_msg: "The file '{{ item.item }}' does not exist."
      loop: "{{ extra_manifests_stats.results }}"
      loop_control:
        label: "{{ item.item }}"
      when: extra_manifests_stats is defined

    - name: Debug extra manifests to be copied
      ansible.builtin.debug:
        msg: "Copying {{ extra_manifests | length }} extra manifest(s): {{ extra_manifests }}"
      when:
        - extra_manifests is defined
        - extra_manifests | length > 0

    - name: Copy extra manifests
      ansible.builtin.copy:
        src: "{{ item }}"
        dest: "{{ repo_root_path }}/generated/{{ cluster_name }}/openshift/{{ item }}"
        mode: "0644"
      loop:
        - "{{ extra_manifests }}"
      when:
        - extra_manifests_stats is defined
        - extra_manifests is defined
        - extra_manifests | length > 0

    - name: Generate boot ISO for agent-based installer
      ansible.builtin.import_role:
        name: redhatci.ocp.generate_agent_iso
      vars:
        gai_cluster_name: "{{ cluster_name }}"
        gai_repo_root_path: "{{ repo_root_path }}"
        gai_pull_secret: "{{ pull_secret }}"
        gai_agent_based_installer_path: "{{ openshift_installer_extract_dest_path }}/openshift-install"
        gai_discovery_iso_name: "agent.iso"
        gai_remote_http_src: true
        gai_http_delegate_host: "{{ inventory_hostname }}"

- name: Setup Virtual Control Plane
  hosts: vm_hosts
  tasks:

    - name: Enable CRB repository
      become: true
      ansible.builtin.command: "dnf config-manager --enable rhosp-rhel-9.4-crb"
      changed_when: false

    - name: Setup sushy tool to emulate OOB interface
      ansible.builtin.import_role:
        name: redhatci.ocp.setup_sushy_tools
      vars:
        cert_state: "QE"
        cert_locality: TLV
        cert_organization: RH
        cert_country: US
        cert_organizational_unit: QE
        fetched_dest: "/tmp/artifacts"

    - name: Destroy pre-installed VMs
      ansible.builtin.import_role:
        name: redhatci.ocp.destroy_vms

    - name: Create VMs
      ansible.builtin.import_role:
        name: redhatci.ocp.create_vms

- name: Boot Bare-Metal Nodes
  hosts: workers
  gather_facts: false
  tasks:
    - name: Boot ISO
      ansible.builtin.import_role:
        name: redhatci.ocp.boot_iso
      vars:
        boot_iso_url: "http://{{ hostvars['bastion']['ansible_default_ipv4']['address'] }}:{{ share_http_iso_port }}/{{ agent_iso_name }}"

- name: Boot Virtual Machines
  hosts: masters
  gather_facts: false
  serial: 1
  tasks:
    - name: Boot ISO
      ansible.builtin.import_role:
        name: redhatci.ocp.boot_iso
      vars:
        boot_iso_url: "http://{{ hostvars['bastion']['ansible_default_ipv4']['address'] }}:{{ share_http_iso_port }}/{{ agent_iso_name }}"

- name: Monitor installation process of agent-based installer
  hosts: bastion
  gather_facts: false
  vars:
    internal_registry: false
    trusted_ca_config_map_name: "external-registry"
  tasks:

    - name: Monitor agent based installation
      ansible.builtin.import_role:
        name: redhatci.ocp.monitor_agent_based_installer
      vars:
        agent_based_installer_path: "{{ openshift_installer_extract_dest_path }}/openshift-install"
        mabi_retry_install_complete_check: true
        cluster: "{{ cluster_name }}"

    - name: Set Kubeconfig
      ansible.builtin.set_fact:
        kubeconfig: "~/project/generated/{{ cluster_name }}/auth/kubeconfig"

    - name: Get OpenShift pull-secret
      kubernetes.core.k8s_info:
        api_version: v1
        kind: Secret
        name: pull-secret
        namespace: openshift-config
      register: pull_secret_raw
      environment:
        K8S_AUTH_KUBECONFIG: "{{ kubeconfig }}"

    - name: Update default pull-secret with additional trusted registries
      kubernetes.core.k8s:
        state: present
        definition: "{{ lookup('template', 'templates/pull_secret.j2') }}"
      environment:
        K8S_AUTH_KUBECONFIG: "{{ kubeconfig }}"
      vars:
        ocp_pull_secret: "{{ pull_secret_raw }}"
        trusted_registries: "{{ additional_trusted_registries }}"

    - name: Configure trusted CA for internal registry
      when: internal_registry | default(false) | bool
      block:
        # In Prow environment, the disconnected registry certificate is in raw string format, we need to re-format it.
        # Based on the env variable SHARED_DIR, we can determine if we are in Prow environment.
        - name: Format disconnected registry certifcate if needed
          when: lookup('env', 'SHARED_DIR') | length > 0
          ansible.builtin.set_fact:
            disconnected_registry_cert_formatted: "-----BEGIN CERTIFICATE-----\n
              {{ disconnected_registry_cert.strip('-----BEGIN CERTIFICATE-----').
              strip('-----END CERTIFICATE-----') | regex_replace('\\s+', '\n')}}\n-----END CERTIFICATE-----"

        - name: Set up external registry CA data
          ansible.builtin.set_fact:
            configmap_data: >-
              {{
                {
                  ((disconnected_registry_url ~ '..' ~ disconnected_registry_port)):(disconnected_registry_cert_formatted | default(disconnected_registry_cert))
                }
              }}

        - name: Set up additional trusted CA for container repo using configmap
          kubernetes.core.k8s:
            kubeconfig: "{{ kubeconfig }}"
            state: present
            merge_type: [merge]
            definition:
              apiVersion: v1
              kind: ConfigMap
              metadata:
                name: "{{ trusted_ca_config_map_name }}"
                namespace: openshift-config
              data: "{{ configmap_data }}"

        - name: Apply image.config.openshift.io configuration change
          kubernetes.core.k8s_json_patch:
            api: config.openshift.io/v1
            kind: Image
            kubeconfig: "{{ kubeconfig }}"
            name: cluster
            patch:
              - op: add
                path: /spec/additionalTrustedCA
                value:
                  name: "{{ trusted_ca_config_map_name }}"
